
FREEZ LEARNABLE PARAMETERS

Learnable parameters per component:

vae: 0 learnable parameters
text_encoder: 0 learnable parameters
text_encoder_2: 0 learnable parameters
unet: 0 learnable parameters
images input shape: torch.Size([10, 3, 512, 512])
model output shape:torch.Size([10, 4, 64, 64])
0.13025
noise shape: torch.Size([10, 4, 64, 64])
bsz: 10
timesteps: tensor([577, 794, 472, 250, 100, 237, 209, 645, 251, 657], device='cuda:0')
add time ids cat: tensor([[1536., 1536.],
        [1536., 1536.],
        [1536., 1536.],
        [1536., 1536.],
        [1536., 1536.],
        [1536., 1536.],
        [1536., 1536.],
        [1536., 1536.],
        [1536., 1536.],
        [1536., 1536.]], device='cuda:0')
Prompt Embeds shape before reshape: torch.Size([10, 77, 2048])
Pooled Prompt Embeds shape before reshape: torch.Size([10, 1280])

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 24574336: <train_test> in cluster <dcc> Exited

Job <train_test> was submitted from host <hpclogin1> by user <s240577> in cluster <dcc> at Sun Apr  6 17:44:42 2025
Job was executed on host(s) <4*n-62-20-4>, in queue <gpuv100>, as user <s240577> in cluster <dcc> at Sun Apr  6 17:44:44 2025
</zhome/20/1/209339> was used as the home directory.
</dtu/blackhole/1b/209339/text-to-image-generation-in-the-medical-domain> was used as the working directory.
Started at Sun Apr  6 17:44:44 2025
Terminated at Sun Apr  6 17:44:58 2025
Results reported at Sun Apr  6 17:44:58 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/bash

### -- set the job Name -- 
#BSUB -J train_test

### -- specify queue --
#BSUB -q gpuv100

### -- set walltime limit: hh:mm -- 
#BSUB -W 10

# request GB of system-memory per core
#BSUB -R "rusage[mem=1GB]"

### -- Select the resources: 1 gpu in exclusive process mode --
#BSUB -gpu "num=1:mode=exclusive_process"

### -- ask for number of cores (default: 1) --
#BSUB -n 4

### -- specify that the cores must be on the same host -- 
#BSUB -R "span[hosts=1]"

### -- Specify the output and error file. %J is the job-id -- 
### -- -o and -e mean append, -oo and -eo mean overwrite -- 
#BSUB -o bash/bash_outputs/train_test_%J.out
#BSUB -e bash/bash_outputs/train_test_%J.err

### -- Need to activate the python environment --
conda activate brain

### -- run in the job --
python src/train.py

------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   11.68 sec.
    Max Memory :                                 2500 MB
    Average Memory :                             2500.00 MB
    Total Requested Memory :                     4096.00 MB
    Delta Memory :                               1596.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                8
    Run time :                                   94 sec.
    Turnaround time :                            16 sec.

The output (if any) is above this job summary.



PS:

Read file <bash/bash_outputs/train_test_24574336.err> for stderr output of this job.

